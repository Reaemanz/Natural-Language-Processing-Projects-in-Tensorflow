{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "09_Lime_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjoUGDuyTdh5"
      },
      "source": [
        "In this notebook we will demonstrate how to interpret a Deep Learning Model using [LIME](https://github.com/marcotcr/lime)(local interpretable model-agnostic explanations), a python package for explaining machine learning classifiers. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVQdTkPzH-Y7",
        "outputId": "1d0dea01-69b6-4c3b-930d-5d0bf45b6c96"
      },
      "source": [
        "# To install only the requirements of this notebook, uncomment the lines below and run this cell\n",
        "\n",
        "# ===========================\n",
        "\n",
        "!pip install pandas==1.1.5\n",
        "!pip install scikit-learn==0.21.3\n",
        "!pip install lime==0.2.0.1\n",
        "!pip install tensorflow==1.14.0\n",
        "!pip install numpy==1.19.5\n",
        "!pip install matplotlib==3.2.2\n",
        "!pip install seaborn==0.11.1\n",
        "\n",
        "# ==========================="
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas==1.1.5 in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.5) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.5) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.5) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas==1.1.5) (1.15.0)\n",
            "Requirement already satisfied: scikit-learn==0.21.3 in /usr/local/lib/python3.7/dist-packages (0.21.3)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.21.3) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.21.3) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.21.3) (1.0.1)\n",
            "Requirement already satisfied: lime==0.2.0.1 in /usr/local/lib/python3.7/dist-packages (0.2.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from lime==0.2.0.1) (0.21.3)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.7/dist-packages (from lime==0.2.0.1) (0.16.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lime==0.2.0.1) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from lime==0.2.0.1) (3.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from lime==0.2.0.1) (4.41.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lime==0.2.0.1) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->lime==0.2.0.1) (1.0.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime==0.2.0.1) (2.5.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime==0.2.0.1) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime==0.2.0.1) (2.4.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime==0.2.0.1) (7.1.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime==0.2.0.1) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime==0.2.0.1) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime==0.2.0.1) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime==0.2.0.1) (2.8.1)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image>=0.12->lime==0.2.0.1) (4.4.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->lime==0.2.0.1) (1.15.0)\n",
            "Requirement already satisfied: tensorflow==1.14.0 in /usr/local/lib/python3.7/dist-packages (1.14.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.36.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.19.5)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.12.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (3.17.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.34.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (3.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (57.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.3.4)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.14.0) (1.5.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (4.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.5.0)\n",
            "Requirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Requirement already satisfied: matplotlib==3.2.2 in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.2) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.2) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.2) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.2) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.2) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib==3.2.2) (1.15.0)\n",
            "Requirement already satisfied: seaborn==0.11.1 in /usr/local/lib/python3.7/dist-packages (0.11.1)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn==0.11.1) (1.4.1)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from seaborn==0.11.1) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from seaborn==0.11.1) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from seaborn==0.11.1) (1.19.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn==0.11.1) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn==0.11.1) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn==0.11.1) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn==0.11.1) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->seaborn==0.11.1) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=2.2->seaborn==0.11.1) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQa4Mi5HH-Y8"
      },
      "source": [
        "# To install the requirements for the entire chapter, uncomment the lines below and run this cell\n",
        "\n",
        "# ===========================\n",
        "\n",
        "# try:\n",
        "#     import google.colab\n",
        "#     !curl  https://raw.githubusercontent.com/practical-nlp/practical-nlp/master/Ch4/ch4-requirements.txt | xargs -n 1 -L 1 pip install\n",
        "# except ModuleNotFoundError:\n",
        "#     !pip install -r \"ch4-requirements.txt\"\n",
        "\n",
        "# ==========================="
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5S86uIWZKVO"
      },
      "source": [
        "We will be building an LSTM model with an embedding layer trained on the fly. We will be following all the preprocessing steps as in the [DeepNN_Example.ipynb](https://github.com/practical-nlp/practical-nlp/blob/master/Ch4/DeepNN_Example.ipynb) notebook in this repo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsCn1xlo_MMX"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "#helper functions to lead the data\n",
        "def load_directory_data(directory):\n",
        "    data = {}\n",
        "    data[\"sentence\"] = []\n",
        "    data[\"sentiment\"] = []\n",
        "    for file_path in os.listdir(directory):\n",
        "        with tf.io.gfile.GFile(os.path.join(directory, file_path), \"r\") as f:\n",
        "            data[\"sentence\"].append(f.read())\n",
        "            data[\"sentiment\"].append(re.match(\"\\d+_(\\d+)\\.txt\", file_path).group(1))\n",
        "    return pd.DataFrame.from_dict(data)\n",
        "\n",
        "# Merge positive and negative examples, add a polarity column and shuffle.\n",
        "def load_dataset(directory):\n",
        "    pos_df = load_directory_data(os.path.join(directory, \"pos\"))\n",
        "    neg_df = load_directory_data(os.path.join(directory, \"neg\"))\n",
        "    pos_df[\"polarity\"] = 1\n",
        "    neg_df[\"polarity\"] = 0\n",
        "    return pd.concat([pos_df, neg_df]).sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "def download_and_load_datasets(force_download=False):\n",
        "    dataset = tf.keras.utils.get_file(\n",
        "      fname=\"aclImdb.tar.gz\", \n",
        "      origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", \n",
        "      extract=True)\n",
        "\n",
        "    train_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
        "                                       \"aclImdb\", \"train\"))\n",
        "    test_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
        "                                      \"aclImdb\", \"test\"))\n",
        "  \n",
        "    return train_df, test_df"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlBTwerPX1EV"
      },
      "source": [
        "try:\n",
        "    from google.colab import files\n",
        "    \n",
        "    if not os.path.exists('aclImdb'):\n",
        "        train,test = download_and_load_datasets()\n",
        "    else:\n",
        "        train = load_dataset('aclImdb/train')\n",
        "        test = load_dataset('aclImdb/test')\n",
        "    \n",
        "except ModuleNotFoundError:\n",
        "    if not os.path.exists('Data/aclImdb'):\n",
        "        train,test = download_and_load_datasets()\n",
        "    else:\n",
        "        train = load_dataset('Data/aclImdb/train')\n",
        "        test = load_dataset('Data/aclImdb/test')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEpQWHnF-hOX"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Dense, Input, GlobalMaxPooling1D\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Embedding, LSTM\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.initializers import Constant\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = 1000\n",
        "MAX_NUM_WORDS = 20000 \n",
        "EMBEDDING_DIM = 100 \n",
        "VALIDATION_SPLIT = 0.2\n",
        "\n",
        "vocab_size = 20000  # Max number of different word, i.e. model input dimension\n",
        "maxlen = 1000 # Max number of words kept at the end of each text"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "830AVGaZBfnf",
        "outputId": "1a80608b-b295-41c3-dc2f-bfbd701667d5"
      },
      "source": [
        "train.columns"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['sentence', 'sentiment', 'polarity'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJo_FLISBhx6"
      },
      "source": [
        "train_texts = train['sentence'].values\n",
        "train_labels = train['polarity'].values\n",
        "test_texts = test['sentence'].values\n",
        "# test_labels = test['polarity'].values\n",
        "\n",
        "labels_index = {'pos':1, 'neg':0} "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZ1G3DH3dDQ4",
        "outputId": "6aee306f-91e4-45a3-fae1-db00d530ff2f"
      },
      "source": [
        "test.columns"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['sentence', 'sentiment', 'polarity'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8I6QgXldKd0",
        "outputId": "e96585e8-3a61-45f1-8873-247b4b6afa13"
      },
      "source": [
        "test_labels = test['polarity'].values\n",
        "test_labels"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, ..., 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfPAZEEKajly"
      },
      "source": [
        "We need to design an sklearn pipeline with our model.\n",
        "What is a pipeline?<br>\n",
        "\n",
        "**Transformer** in scikit-learn - some class that have fit and transform method, or fit_transform method.\n",
        "\n",
        "**Predictor** - some class that has fit and predict methods, or fit_predict method.\n",
        "\n",
        "**Pipeline** is just an abstract notion, it's not some existing ml algorithm. Often in ML tasks you need to perform sequence of different transformations (find set of features, generate new features, select only some good features) of raw dataset before applying final estimator. Pipeline gives you a single interface for all 3 steps of transformation and resulting estimator. It encapsulates transformers and predictors inside"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibekacAMMTsr"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.pipeline import TransformerMixin\n",
        "from sklearn.base import BaseEstimator\n",
        "\n",
        "\n",
        "class TextsToSequences(Tokenizer, BaseEstimator, TransformerMixin):\n",
        "    \"\"\" Sklearn transformer to convert texts to indices list \n",
        "    (e.g. [[\"the cute cat\"], [\"the dog\"]] -> [[1, 2, 3], [1, 4]])\"\"\"\n",
        "    def __init__(self,  **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        \n",
        "    def fit(self, texts, y=None):\n",
        "        self.fit_on_texts(texts)\n",
        "        return self\n",
        "    \n",
        "    def transform(self, texts, y=None):\n",
        "        return np.array(self.texts_to_sequences(texts))\n",
        "        \n",
        "sequencer = TextsToSequences(num_words=vocab_size)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Padder(BaseEstimator, TransformerMixin):\n",
        "    \"\"\" Pad and crop uneven lists to the same length. \n",
        "    Only the end of lists longernthan the maxlen attribute are\n",
        "    kept, and lists shorter than maxlen are left-padded with zeros\n",
        "    \n",
        "    Attributes\n",
        "    ----------\n",
        "    maxlen: int\n",
        "        sizes of sequences after padding\n",
        "    max_index: int\n",
        "        maximum index known by the Padder, if a higher index is met during \n",
        "        transform it is transformed to a 0\n",
        "    \"\"\"\n",
        "    def __init__(self, maxlen=500):\n",
        "        self.maxlen = maxlen\n",
        "        self.max_index = None\n",
        "        \n",
        "    def fit(self, X, y=None):\n",
        "        self.max_index = pad_sequences(X, maxlen=self.maxlen).max()\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X, y=None):\n",
        "        X = pad_sequences(X, maxlen=self.maxlen)\n",
        "        X[X > self.max_index] = 0\n",
        "        return X\n",
        "\n",
        "padder = Padder(maxlen)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mtEN5BjbyKM"
      },
      "source": [
        "We will only train for 2 epochs. A better model could be trained with more epochs and early stopping."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XvXEYGBMWlW",
        "outputId": "4ea00082-b2b0-4760-b083-77b033daa59b"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Bidirectional, LSTM\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "batch_size = 64\n",
        "max_features = vocab_size + 1\n",
        "\n",
        "#Training an LSTM with embedding on the fly\n",
        "def create_model(max_features):\n",
        "    \"\"\" Model creation function: returns a compiled LSTM\"\"\"\n",
        "\n",
        "\n",
        "    rnnmodel = Sequential()\n",
        "    rnnmodel.add(Embedding(MAX_NUM_WORDS, 128))\n",
        "    rnnmodel.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "    rnnmodel.add(Dense(1, activation='sigmoid'))\n",
        "    rnnmodel.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "    return rnnmodel\n",
        "\n",
        "\n",
        "# Use Keras Scikit-learn wrapper to instantiate a LSTM with all methods\n",
        "# required by Scikit-learn for the last step of a Pipeline\n",
        "sklearn_lstm = KerasClassifier(build_fn=create_model, epochs=2, batch_size=32, \n",
        "                               max_features=max_features, verbose=1)\n",
        "\n",
        "# Build the Scikit-learn pipeline\n",
        "pipeline = make_pipeline(sequencer, padder, sklearn_lstm)\n",
        "\n",
        "pipeline.fit(train_texts, train_labels);"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Epoch 1/2\n",
            "25000/25000 [==============================] - 1951s 78ms/sample - loss: 0.4927 - acc: 0.7689\n",
            "Epoch 2/2\n",
            "25000/25000 [==============================] - 1925s 77ms/sample - loss: 0.3622 - acc: 0.8466\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTph3cZ2anzx",
        "outputId": "d469ca0d-836c-4911-a194-3f9b01253b94"
      },
      "source": [
        "y_preds = pipeline.predict(test_texts)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 201s 8ms/sample\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KKnIf5BcnQn",
        "outputId": "5f7f975d-d7da-4618-f63d-8f9ac3162c97"
      },
      "source": [
        "print('Test accuracy: {:.2f} %'.format(100*accuracy_score(y_preds, test_labels)))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 79.89 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "jd9mzgXrZ9ys",
        "outputId": "28ee9c4e-f38f-4b42-e7b2-b032230892b1"
      },
      "source": [
        "# We choose a sample from test set\n",
        "idx = 11\n",
        "text_sample = test_texts[idx]\n",
        "class_names = ['negative', 'positive']\n",
        "\n",
        "print('Sample {}: last 1000 words (only part used by the model)'.format(idx))\n",
        "print('-'*50)\n",
        "print(\" \".join(text_sample.split()[-1000:]))\n",
        "print('-'*50)\n",
        "print('Probability(positive) =', pipeline.predict_proba([text_sample])[0,1])\n",
        "print('True class: %s' % class_names[test_labels[idx]])\n",
        "\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from collections import OrderedDict\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "\n",
        "explainer = LimeTextExplainer(class_names=class_names)\n",
        "explanation = explainer.explain_instance(text_sample, pipeline.predict_proba, num_features=10)\n",
        "\n",
        "weights = OrderedDict(explanation.as_list())\n",
        "lime_weights = pd.DataFrame({'words': list(weights.keys()), 'weights': list(weights.values())})\n",
        "\n",
        "sns.barplot(x=\"words\", y=\"weights\", data=lime_weights);\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Sample {} features weights given by LIME'.format(idx));"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample 11: last 1000 words (only part used by the model)\n",
            "--------------------------------------------------\n",
            "I had the privilege of being one of the Still photographers on the set of \"Grand Champion\" and enjoyed every minute of the 42 days I worked on the movie. I have been in the Photography business for 25 years and have worked on 16 movies and I can't think of a time when I enjoyed providing my craft more. The Kids were wonderful to work with and little Emma Roberts has so much energy she's a real trip. She even grabbed one of my camera during the stockshow scene rehearsal and started shooting. Some of her images were used for PR. I could have made more money working for a production with a bigger budget but I doubt I would have had the fun and been around so many great actors and the great people of West Texas as I was.\n",
            "--------------------------------------------------\n",
            "\r1/1 [==============================] - 0s 125ms/sample\n",
            "Probability(positive) = 0.43980047\n",
            "True class: positive\n",
            "5000/5000 [==============================] - 40s 8ms/sample\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEwCAYAAACpLzYDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debhd49nH8e9PImIWpMZEzKQUbVBqnmeqhpiKl4ZWqm8NpaaGKkW1FK2mRRWtuZUSr7EihiLmqYipCUrMqSkJ9/vH8xxWTvZZ5yRnT8n+fa7rXGevYa/n3muvve/1DGttRQRmZmYdma3RAZiZWXNzojAzs1JOFGZmVsqJwszMSjlRmJlZKScKMzMr5UTRwiQNk3RpE8SxiKQ7JU2UdGaj42kmks6XdHwX1/2jpJNrHVOFcveSdHMDyg1Jy9W73FbkRNEAktaTdI+k9yS9LeluSWs2Oq7pIWmopDGSPpH0x3bLekm6WtJL+cO8USebGwK8CcwXEYd3M66GfFnWSkQcHBE/rca2avXFGhGXRcQW1d5uvUjaT9JdHSy7Q9KB+fFGeR/+td06q+X5dxTmhaQPJP238Pejmr6QGurZ6ABajaT5gOuB7wJXAr2A9YFPGhnXDHgVOBnYEpizwvK7gLOAq7qwraWAp6IJrv6U1DMipjQ6DmtaE4B1JC0UEW/lefsCz1ZYd7WIGFu/0GrHNYr6WwEgIv4SEZ9GxEcRcXNEPAYgaVlJt0t6S9Kbki6TtEDbk/NZ+pGSHstnLBfkppsbc9PNrZL65HUH5DObIZJelfSapCM6CkzS13NN511Jj5bVBCLi2oj4G/BWhWWTIuKsiLgL+LRsZ+TayL7Aj/JZ12aSZpN0tKTn8364UtKChedcJek/uUZ2p6Qv5/lDgL0K2/p7nj/VmXSx1pHPEsdLOkrSf4CLysqX1FvSpXn+u5IekLRIhde1f1v5efo5SVcVpsdJWj0/XknSLbl2+Yyk3SrFmqd/lN/HVyUdWKGW0EfSDflYuE/Ssvl5d+blj+Z9s7ukhSVdn1/H25JGS6r4nSBpixzbe5J+I2lU4Uz78zNySb+V9It2z71O0mH58eKSrpE0QdKLkg4trDcs7+s/5fiflDSoUjwF20h6IX9WzsjvXa/8elYtbPtLkj6U1LeT7XVmEvA3YHDebg9gd+Cybm63qTlR1N+zwKeSLpa0dduXeoGAU4HFgZWBfsCwdut8C9iclHS2B24EjgH6kt7TQ9utvzGwPLAFcJSkzdoHJWkJ4AZSLWFB4Ajgmip8sEpFxH6kD9npETFPRNwKfB/YCdiQtB/eAc4rPO1G0uv5EvBQfj4RMbzdtrbvYhiLkl7zUqRmsLLy9wXmJ70vCwEHAx9V2OYoYP38xbU4qea4DoCkZYB5gMckzQ3cAvw5v57BwG8kDWy/QUlbAYcBmwHLARtVKHcwcCLQBxgL/AwgIjbIy1fL++YK4HBgPOm4WYR0DE1Tq5O0MHA18OP8mp8B1q1QNsBfgN0lKT+3D+m4uzwnob8DjwJLAJsC/ytpy8LzdwAuBxYARgDndlBOm28Cg4CvAjsC/xMRk/I29i6stwdwW0RM6GR7XfEn4Nv58ZbAE6Qa9izLiaLOIuJ9YD3SB/L3wARJI9rOSiNibETcEhGf5IP6l6QvrKJzIuL1iHgFGA3cFxEPR8THwF+BNdqtf2JEfBARjwMXkT407e0NjIyIkRHxWUTcAowBtqnOK58uBwPHRsT4iPiElCh3kdQTICIujIiJhWWrSZq/G+V9Bvwk7/OPOil/MunLcrlcI3wwv6dTiYgXgInA6sAGwE3Aq5JWIr2foyPiM2A74KWIuCgipkTEw8A1wK4V4twNuCginoyID5n2BALgrxFxf24+uyyX35HJwGLAUhExOSJGd9D8tw3wZK5FTgF+Dfyng22OJh3b6+fpXYB7I+JVYE2gb0SclGudL5A+A4MLz78rH4OfApcAq5XED3BaRLwdEf8mNXW2HdsXA3u0JSxgn7y9bouIe4AFJa1IShh/6mDVh3Jtre1vyw7Wa3pOFA0QEU9HxH4RsSSwCums9Sz4fATQ5ZJekfQ+cCmwcLtNvF54/FGF6XnarT+u8PjlXF57SwG7Fg9sUkJbbDpfXjUsBfy1EMfTpCasRST1kPTz3Cz0PvBSfk77fTQ9JuQk22n5pC+bm0hnyK9KOl3S7B1sdxTprH+D/PgOUpLYME+3lbV2u/2+F6mW097iTP1ejquwTvEL/EOmPRaKziDVOm7OzTdHd7DeVOXmZDK+0op52eV88YW9J180yywFLN7utR5D2q8dxd+77QShAxWP7Yi4Lz9/o5yclyPVUKrlEmAoqbb+1w7W+WpELFD4u6mK5deVE0WDRcS/gD+SEgbAKaQzslUjYj7Smb4qP7vL+hUe96dyNXkccEm7A3vuiPh5N8ueEeOArdvF0jvXoPYkNTFsRmoCGpCf07aPKp0RfwjMVZhu/yXc/jkdlp/PvE+MiIGk5pft+KIZor22RLF+fjyKaRPFOGBUu7LmiYjvVtjea8CShel+FdbpslwrOzwiliE1+RwmadPOys1n6UtWWK/NX0g1sKWAtUk1JEiv9cV2r3XeiOhOrbXs2L6Y9PnZB7i63clAd10CfI9UC/+witttSk4UdZY7Lg+XtGSe7kc6+/pnXmVe4L/Ae7nf4MgqFHu8pLmUOn33B66osM6lwPaStsxn7b2VOnorfiFI6impN9ADaFu/Z2H5HHk5QK+8vKsJ73zgZ/mLBkl9Je2Yl81LGiH2FunL/5R2z30dWKbdvEeAPfPr2oppm/K6XL6kjSWtmjsx3yc133zWwXZGkc4454yI8aRmma1ITVcP53WuB1aQtI+k2fPfmpJWrrC9K4H9Ja0saS6gS9dXFEy1byRtJ2m5/L68R6o1VXotNwCrStopv8eHULnGA0BuPnsT+ANwU0S8mxfdD0xUGjgwZ34/VlH3hoYfKalP/hz9gKmP7UtJfRh703HzUBvlY/Tzv7KVI+JF0nF0bDdin2k4UdTfRNJZ1n2SPiAliCdIHYuQOiK/Svrg3gBcW4UyR5GaGG4DfhER01wcFRHjSGfqx5CGAI4jJamOjpHjSM1cR5M+iB/leW2eyfOWIDXVfERqeuiKs0nNBDdLmkjaR2vnZX8iNTG8AjzFFwm2zQXAwNy08bc87wekTv+2Zp2/Ua6s/EVJHbvvk5qkRtFB23dEPEtK+qPz9PvAC8DduQ2eiJhI6uwdTDob/g9wGjBHhe3dSOof+Afp/Wx77V0dWj0MuDjvm91IAwJuzTHeC/wmIv5Rodw3SX0mp5MS9EBS/1VZuX8m1fr+XNjOp6Qa2OrAi3yRTLrTv3Qd8CDpZOAG0vvfVt440mCHIL8HJdYlHaOf/3XS5EVE3JX7XjrSNsKs7e+sTl9Nk1LlviubFUgaQPpAzh6+NmCWk2sdTwBz1PP9zaOXxgN7VUoszUTShcCrEXFcpytbh1yjMJuJSPpmbtbrQ6p5/L0eSSI3SS4gaQ5SrVNMW5trKvlEaWcKtQybMU4UZjOXg4A3gOdJfQqVOr1rYZ1c5pukZryd8lDipiTpp6Ta1hm5P8G6wU1PZmZWyjUKMzMr5URhZmalZrm7xy688MIxYMCARodhZjZTefDBB9+MiIr3dpvlEsWAAQMYM2ZMo8MwM5upSHq5o2VuejIzs1JOFGZmVsqJwszMSjlRmJlZKScKMzMr5URhZmalnCjMzKyUE4WZmZWa5S64a+9rR3b2w1bV8+AZHf0ippnZzMs1CjMzK+VEYWZmpZwozMyslBOFmZmVcqIwM7NSThRmZlbKicLMzEo5UZiZWSknCjMzK+VEYWZmpZwozMyslBOFmZmVcqIwM7NSDU0UkraS9IyksZKOrrD8YEmPS3pE0l2SBjYiTjOzVtawRCGpB3AesDUwENijQiL4c0SsGhGrA6cDv6xzmGZmLa+RNYq1gLER8UJETAIuB3YsrhAR7xcm5waijvGZmRmN/eGiJYBxhenxwNrtV5J0CHAY0AvYpD6hmZlZm6bvzI6I8yJiWeAo4LhK60gaImmMpDETJkyob4BmZrO4RiaKV4B+hekl87yOXA7sVGlBRAyPiEERMahv375VDNHMzBqZKB4Alpe0tKRewGBgRHEFScsXJrcFnqtjfGZmRgP7KCJiiqShwE1AD+DCiHhS0knAmIgYAQyVtBkwGXgH2LdR8ZqZtapGdmYTESOBke3mnVB4/IO6B2VmZlNp+s5sMzNrLCcKMzMr5URhZmalnCjMzKyUE4WZmZVyojAzs1JOFGZmVsqJwszMSjlRmJlZKScKMzMr5URhZmalnCjMzKyUE4WZmZVyojAzs1JOFGZmVsqJwszMSjlRmJlZKScKMzMr5URhZmalnCjMzKyUE4WZmZVyojAzs1JOFGZmVsqJwszMSjlRmJlZKScKMzMr5URhZmalnCjMzKyUE4WZmZVyojAzs1JOFGZmVsqJwszMSjlRmJlZKScKMzMr1dBEIWkrSc9IGivp6ArLD5P0lKTHJN0maalGxGlm1soaligk9QDOA7YGBgJ7SBrYbrWHgUER8RXgauD0+kZpZmaNrFGsBYyNiBciYhJwObBjcYWI+EdEfJgn/wksWecYzcxaXiMTxRLAuML0+DyvIwcAN9Y0IjMzm0bPRgfQFZL2BgYBG3awfAgwBKB///51jMzMbNbXyBrFK0C/wvSSed5UJG0GHAvsEBGfVNpQRAyPiEERMahv3741CdbMrFU1MlE8ACwvaWlJvYDBwIjiCpLWAH5HShJvNCBGM7OW17BEERFTgKHATcDTwJUR8aSkkyTtkFc7A5gHuErSI5JGdLA5MzOrkYb2UUTESGBku3knFB5vVvegzMxsKr4y28zMSjlRmJlZKScKMzMr5URhZmalnCjMzKyUE4WZmZVyojAzs1JOFGZmVsqJwszMSjlRmJlZKScKMzMr5URhZmalnCjMzKyUE4WZmZVyojAzs1JdShSSlpU0R368kaRDJS1Q29DMzKwZdLVGcQ3wqaTlgOGk37r+c82iMjOzptHVRPFZ/unSbwLnRMSRwGK1C8vMzJpFVxPFZEl7APsC1+d5s9cmJDMzayZdTRT7A+sAP4uIFyUtDVxSu7DMzKxZ9OzieptHxKFtEzlZfFyjmMzMrIl0tUaxb4V5+1UxDjMza1KlNYrcL7EnsLSkEYVF8wJv1zIwMzNrDp01Pd0DvAYsDJxZmD8ReKxWQZmZWfMoTRQR8TLwMqkj28zMWlBXr8zeWdJzkt6T9L6kiZLer3VwZmbWeF0d9XQ6sH1EPF3LYMzMrPl0ddTT604SZmatqbNRTzvnh2MkXQH8DfikbXlEXFvD2MzMrAl01vS0feHxh8AWhekAnCjMzGZxnY162r9egZiZWXPqUme2pF9XmP0eMCYirqtuSGZm1ky62pndG1gdeC7/fQVYEjhA0lk1is3MzJpAV4fHfgX4RkR8CiDpt8BoYD3g8RrFZmZmTaCrNYo+wDyF6bmBBXPi+KTyUzonaStJz0gaK+noCss3kPSQpCmSdpnRcszMbMZNzwV3j0i6AxCwAXCKpLmBW2ekYEk9gPOAzYHxwAOSRkTEU4XV/k26S+0RM1KGmZl1X5cSRURcIGkksFaedUxEvJofHzmDZa8FjI2IFwAkXQ7sCHyeKCLipbzssxkswwq+cc436lbW3d+/u25lmVltdXbB3UoR8S9JX82zxuX/i0paNCIe6kbZSxS2B6lWsXY3tmczgVEbbFi3sja8c1TdyjKblXVWozgMGMLUtxhvE8AmVY9oBkgaQoqT/v37NzgaM7NZS2cX3A3J/zeuQdmvAP0K00vmedMtIoYDwwEGDRoU3Q/NzMzadPU243NJOk7S8Dy9vKTtuln2A8DykpaW1AsYDIzo5DlmZlZnXR0eexEwCVg3T78CnNydgiNiCjAUuAl4GrgyIp6UdJKkHQAkrSlpPLAr8DtJT3anTDMzm35dHR67bETsnn9Dm4j4UJK6W3hEjARGtpt3QuHxA6QmKTMza5Cu1igmSZqT1IGNpGXpxoV2ZmY28+hqjeInwP8B/SRdBnyDdCGcmZnN4rqaKPYFbgCuBl4AfhARb9YsKjMzaxpdTRQXAOuTbrexLPCwpDsj4uyaRWZmZk2hq7fw+IekO4E1gY2Bg4EvA04UZmazuK7+cNFtpDvG3ku6vfiaEfFGLQMzM7Pm0NVRT4+RrqNYhfTbFKvkUVBmZjaL62rT0w8BJM1LGu10EbAoMEfNIjMzs6bQ1aanoaTO7K8BLwEXkpqgzMxsFtfVUU+9gV8CD+Zbb5iZWYvoatPTL2odiJmZNaeudmabmVmLcqIwM7NSThRmZlbKicLMzEo5UZiZWSknCjMzK+VEYWZmpZwozMyslBOFmZmVcqIwM7NSThRmZlbKicLMzEo5UZiZWSknCjMzK+VEYWZmpZwozMyslBOFmZmVcqIwM7NSThRmZlbKicLMzEo5UZiZWSknCjMzK9XQRCFpK0nPSBor6egKy+eQdEVefp+kAfWP0systTUsUUjqAZwHbA0MBPaQNLDdagcA70TEcsCvgNPqG6WZmTWyRrEWMDYiXoiIScDlwI7t1tkRuDg/vhrYVJLqGKOZWctrZKJYAhhXmB6f51VcJyKmAO8BC9UlOjMzA6BnowOoBklDgCEA/fv3n2rZg2d8uxEhTeXfJ61at7L6n/B4h8vu/v7ddYujIxveOarRIQBw7uF/r1tZQ8/cvuL8n+29S91iOPbSqztc9vTPbq9LDCsfu0mHy4YNG1aXGDor68qr1qpLDLvten+Hy1a7+qa6xADw6C5bdmm9RtYoXgH6FaaXzPMqriOpJzA/8Fb7DUXE8IgYFBGD+vbtW6NwzcxaUyMTxQPA8pKWltQLGAyMaLfOCGDf/HgX4PaIiDrGaGbW8hrW9BQRUyQNBW4CegAXRsSTkk4CxkTECOAC4BJJY4G3ScnEzMzqqKF9FBExEhjZbt4JhccfA7vWOy4zM/uCr8w2M7NSThRmZlbKicLMzEo5UZiZWSknCjMzK+VEYWZmpWaJW3iYmc0qunpbjXpyjcLMzEo5UZiZWSknCjMzK+U+CjOzrOz2363MicLMGq6ev0dh089NT2ZmVsqJwszMSrnpyazFlf1EqRm4RmFmZp1wojAzs1JOFGZmVsqJwszMSjlRmJlZKScKMzMr5URhZmalnCjMzKyUE4WZmZVyojAzs1JOFGZmVsqJwszMSvmmgGYNcuylVzc6BLMucY3CzMxKuUZhLWnomds3OgSzmYZrFGZmVsqJwszMSjlRmJlZKScKMzMr1ZBEIWlBSbdIei7/79PBev8n6V1J19c7RjMzSxpVozgauC0ilgduy9OVnAHsU7eozMxsGo1KFDsCF+fHFwM7VVopIm4DJtYrKDMzm1ajEsUiEfFafvwfYJEGxWFmZp2o2QV3km4FFq2w6NjiRESEpOhmWUOAIQD9+/fvzqbMzKydmiWKiNiso2WSXpe0WES8Jmkx4I1uljUcGA4waNCgbiUdMzObWqOankYA++bH+wLXNSgOMzPrRKMSxc+BzSU9B2yWp5E0SNIf2laSNBq4CthU0nhJWzYkWjOzFtaQmwJGxFvAphXmjwEOLEyvX8+4zMxsWr4y28zMSjlRmJlZKScKMzMr5URhZmal/At3ddD/hMcbHYKZ2QxzjcLMzEo5UZiZWSknCjMzK+VEYWZmpZwozMyslBOFmZmVcqIwM7NSThRmZlbKicLMzEopYtb6QThJE4CXu7mZhYE3qxBOdzVDHM0QAzRHHM0QAzRHHM0QAzRHHM0QA3Q/jqUiom+lBbNcoqgGSWMiYpDjaI4YmiWOZoihWeJohhiaJY5miKHWcbjpyczMSjlRmJlZKSeKyoY3OoCsGeJohhigOeJohhigOeJohhigOeJohhighnG4j8LMzEq5RmFmZqWcKJqIpJn2h6QkqdEx1IqkdSWt2Og4zBrFiaITSubJj+epYTkLA2MlLVirMmpB0gBJG0dEzIrJQtLXgT8CkyXN0eBwKmqG/V6MoVHxNMN+mFU5UXRuI2A9SfsDF0iaqxaFRMSbwPeBeyT1qUUZNfI14BJJm9YiWXS0vXp8KUiaDVgOuBYYABzUTLU+SWtLmjOao6NxBUlzSZq7EScNktS2HyTtLumb9Sw/lzvN92mleTUot6PPSNXKdmd2JyR9FTgPWBI4LCKuqnF5WwPnAoMi4p1altVdbR9OSd8FDgG+GxGjix/aamw/P94ZmAw8GxHPtF9ebYXXNjfwAun35VfMCb3hJP0Q2Aw4JCJeyvNqtj86ieUQYGfgfmB+4EcR8d96x5FjOQL4FvA/EfF0Yf5sEfFZDcstHqvbAHMB/4yI8bUsu125ewGfAb0i4uJqluMaRQfasnREPATcDTwD9JTUr5blRsSNwFBgTLPXLPIX6XbA6sDrwG8lbVGtM8rCB2BP4BTgAGCopG8Vyq/6mWv+YLd94S4A3Ay8AexW7bJmRP4i2h3YLSJeys1/8zXoTH6zHMtOpFrXPMAHjWgGkrQCsG1ErAOMk7S5pKMAapkk8vbbjtUDgXOATYEHJS0fEZ/VqmZRKPd/ge8AU4Bj8memapqmGt1MCmeTywCvAccDKwI/AvpIGg4sS3qfnq12+RFxo6ShwL2S1o2It6tdRjVI6g+cDXwb+Depme5MSUMjYlQ1znAl7Q7sCKwBBClZbJA3fW0tzqDbvlQkHQSsQkoSx5Ne25wRcWa1y+yKwv5cjFTLGSRpC2ADYICkr9SzFippADAnqQ9nd2AhYPv82fm60i0lptSw/PbH1wRgDknXAG+RToS/LmmBiPhxreIoxLMB8A1go4gYJ+ll4G5J60XEs7WqWUiaH1gzIjaSdAzppPaKfKx+VI0yXKOooHCmfAXwU9KXxMvAmaQD4Uzgn8CXahjDjcBRwK31aOecHoWzxcnAoxFxd0SMA/4C/AO4WLmDuwrFLQPsAqwSER8DVwPPAttK2qEK268o11oOBS4AegH9gQuB/SSdWqtyOzFf/n8pqWnjKOBBYEPgRmDlegWS++yOJtUkhwEHR8QWEfGJpINJZ7e9alh+sclltXzm/g6wLzAWOCsiDiR9dj+uUc1T+f9sSn2X+wBfISVwRcTPSd8VT0tarlpJosL3QQ9gbkm/BwYBu0fEp8Dukqpz76eI8F+7P2At4BGgH3BGfnwB6YxpAPBNYP06xTJPo/dHIZa2Pq0FC/NuBc4tTO9P+iLbYEa2XZjeEVg2Pz6J9IW4Yp5ejPRFtEgNX+sxwBH5cS/gYOAsUg3jLmDhOu/7Q4CLgZ+Q7vJZXPYt4GlgyTrFslveF6vm6R+QTqr2AQ7K79WqdYrlCOB2UqIcBixeWDYUeJR0klHtclV4/KXCcXIacCqpj7Ft+Q+BFWoQw0Bgjvz4f0k1qhXy9LeBx6p1TNT8jZyZ/oDZ8v8tSO3uW+SDflPgKuDP7d/w9l9ws/ofsDVwB/Dz/MFcCLgHuCwfnP8C1pjefdOWEAvJaDgwGhiQp48B7gUG5ukeNX6dOwHXtZWX543Kr3e2Ou/z/fI+XprU5HRZPiZ7A9uRmhqq/mVYIY62z8eVpCbZtfL04sC2wOXAr+oRSy53N+Dm/PgPwFOkk4qBwKL5M1vThEWqdd5Aqk0fDcxNGoxyMvD1Kpe1BnBofvw94ElS/9m3SKPzDgeeB34NPAR8uVple9QTU/VJ9IlCG6+kXwOXRsT9ks4mVf1/FRGPNSzYBlK6puB80pnjHqRa1fp5ZNCxwCRgTERcP53b3ZHUtn2gpEUi4vU8/5fAasCBEfGipJOBdYEtgSlRw4NX0gKks1WREuOcwAnA1hExoVblVohjO1JSGEZqVtkReBhYnvSF8AjQOyJeqUMsA+KLEVbnACsAO0VuB6/nqKvc7LMm6fcXtiYlzONICeN+UsJ6ISIm1TCGwaSa7S6kE6f+EbG1pC/l6X8Dp0bEJ1UoS6RRbkeQksAypNrbrqQEcj/pRHZ1Uof2WxHR3d/l+UI9Mv/M8Ec62G4HfgacnuddBVxC+nJ6GFi90XE2YL8Uq9gbkc60N84H5oA8f5mOntOF7S9Ear5ahpR8LiV1BrYtPw94gi+aoRaq42tfnNR8cTPpWorV6rzv5yM18exHSgw3te1f4CXgRGCuOsXyPeAmUlPsj/O8K4ARwNx13i9bk0Z8QTqDv5AvmsHOIzUTL1iHOHYiJasf5H0ze56/VH7vqtI0SuoLbWt2PTV/9q4tLN8H+B2pebQmr7upOkkbJZ8pn0ZqS+wJrJ0X7Uca7nckcHJEPNKQABsoIkLSBnl0zdukM7ZzgI0jDc3cBDhKhSvKIx+9XTSJdAZ0POmseSKwmaQN87YOIXXcDpPUMyLeqsbr6oqIeDUiziV9IewTEY/Wq2xJAyPifVI78yJ59lKS1gC2IiXP4RHxYR1i2QbYC9ibNNpvJYCI2J2UtP5Y4/I/7zTOs74ObJ5j+IB0XP42DxH9KumzWtWRgh10hvcEbgM2j4gtI2JyHh57NPBx5JpxFcwPnCvpItJ309lAf0mHAkTEJcADpPfl0yqVOZWWHR5baG5aiLQfjgL6kM6W28bL94mIb7YNM6tn1brJLAFsEhHfkXQWqelnQB4eexpw3Ix+MCNioqTbSZ20PyE1GZwIbK10y4w5SWdrp0cNh1p2EmPNv4yLJK0DXC7pFPIoMuA/pPb380iJc++oT3PTuqSz9hOBHUgnToPzsmUiYntJS9QyhsJnbh1Jz5KaAjcurHIMqTN3XeA7EfFirWKQ9B3SxbeTSO/F2cA2klYm9WkeAOwRVWzyiojnJD0KDAGOiojLJL1NulOAIuLsiPiD0rU071er3KKWTRQ5SWxBGsE0mvSGvwasGxH/zWfKu0j6cUS81/acxkXcUP8C9pC0YEScLOkjUvv4W6RmiBu6mUSvILW7ngu8Q6qx7Elq9lmG1MxQ9Q9/M5LUCxgHvEJqg36N1JF9OKmPYgdSR361zlbLYpmPNEBhCunk6flIF7OhdDX+ypIOr1XCKpzFi3Th4xmkfdOPdH3E66Qh/neTjscptTyZyGfwO5AS9lkAEdaqrewAAAhCSURBVHG80m1dDiMl0d2jcEV4FZ1PGsF1mKS3I+IKSW8Av5H0VkRcWqskAbRuHwVpZMQFwHp5+kTSqJZlSVX7x0kdrA2PtUH7Z03gF3wx/O5kUrNT28iXXkDP/LgqI79IzQbPAfvn6d5A30bvizru83XycfhlUoIcQWr+HEK6NcNP6hhL2+iyA0g1vR+TOks3yfMeooajm4ClC4+/1G7ZRqSO4sPyMXk+sGgNYmg71tsG/ZwBzE5K2iOLn4G8vGe1Y6gQ0/ak5sgtSQMbRhf3Va3+WrJGoXTF9a9JVere+czlTOBj4Peks9qjo/tnyjOzd0hJ8xxJE4FbSJ2I8+dlUyJfQFSt/RMRD0naBbgtN/f9hvSetIpx+e9i4DekYZfvR8S1kj4lNbnUXIWmrz+QvpCuIDXxvA18OyKeqFH52wBnSVqJdP3I1pKeA96NiJ9ExB1KV18/EBG/VLoR4QfVjiO+uEBuQK69LEcaMv0JsGOkPomD8pn936hR/0C7mP4uaTLpJO4D4ICoQ227ZYbHFvokViO1sU4kncHdB5wf+WZvknoDn0XEpFZKEoX9szap8/TNiLhH6d5We5CG4X0ZOCnSFae1jGUV4KOIeL6W5TSrfIyeCsxLqlGtVMeye5FG2VxJqtGdCKxHOoPdOSLGqrY3uduS1E+1DzAHaZjpnvk/wH4RMUXShcAzEXFatT+nuV+mf0RcLun7wP+QkvQKpLslHxIR10jaj9S3uV29j9U8BDeiTkO1WyZRAEjanjQOuTfpwqWnSJ1iNwN/iohXGxhew0naljQ8+J+kZPFRROyZly1LuqZhT9JFRq+1ShJthPxFsClp6OXgyNcv1LjMdUjNrlcCH5Ha4a8lNbGcT2qCOiXS7SFqUf4WpOHoo0n3VVuNdOuctUh3p90mJ4nlSX0W70bEczWIY1tSf9mlpFr18fn/l0l9FCuRrgRfFdg3Ip6qdgzNpmUShaRFgGtIF2/9S+mmewuTmjZ2IL3xp0UNL9BpNnnEV++IeCV3yF0O/C4iblH6kabzSBfuHJbXn510BeoxUYObIdq0JM0eEZPrVNaSpERxMKnpa3ZgQm76OgC4o1ZnzpI2BX5LqsEsShqB2Jc02OSRiNgir/cdUv/NsKjChWwl8WxOqtk8GhF75RF4y5BuUXMnaYBBj3qd0TdaK11HMYn0ehfK078jDXMbRDqDurnFksRcpFE0PSX1ijRapCdp6CXAh6TO/tkLT1uRdK+junxxGdQrSeSyxkfEH0id1buQrps4JS+7oMbNK++TmpUuI/XNfEq6NcmdpJv6DZD0PdJIuEtrmSQAIuIW0t0GtpG0e0R8Emk004qkk6u3WyVJQAsliki35rgG2ETSKvkDeBWpQ3sgaRRHy4h0bcCFpAR6pNItKy4Bfinpa7kNujdpCOT8+TlPkC60a4mhqq0q0oWF+5FqFe8q3U681mU+kPvEZouIf5FqrvMDY0h3R/0psD6wZ0Q8Wet4ckzXkfpKTpU0TNJOpFrFw/Uov5m0TNMTfF61PohUi3iIdNa0D+keMcdHHa+8baRiZ2Su8g8m3UxsOKnp4RekpLET8MOIGCmpR63apq151bPpq0LZK5Ku35gd+D/SL8bV9AeIOohjJ9JJ5vWkz8ML9Y6h0VoqUcDnFxGtS+ooG0lqavk96TL8ml/E1GiF0U3LAK9GxMdKt4XYn3T171mkYYDzApMj4v4GhmstTtJA0vUCF0TEGw2MY0Pg5XoMKmhGLZcoiiRtTBqGeFAr1CYKSWJLUnIcRRpVcjqpSn0A6Urgy6Kad54064ZG1mosafVEsRjph8hb5ktR0lqkM7Qb86xtSf00x5KGAO5Puur1t6Thsa17gJgZ0OKJotXkK9BfAsZHxDfyvK+RfvhkYdJdclck3f3yoFYa1WFmHWuZUU+tqu3GavmK67VJV5KuIemHABHxIOm2BO+RLrKbQLqYaY6GBGxmTcc1ihag9AtyJ5Du17QY6X5CBwFntt2Oo+0WxfkWJvO6NmFmbVyjmMXl6yMGk25V8gDpV/qOI41JP0nSMQA5ScwWER87SZhZUUvePbbFTCZd9XoS6fqRnfP8IPVNfNS2YiPGqJtZ83ONYhaXb7/8OOnXt06MiOfzmPCRwHMRcWvhB2LMzKbhPooWkG+I+H1SZ/ajwHbA4RFxQ0MDM7OZghNFi5A0N6npqQ/wSkQ80Eq/t2FmM86JwszMSrmPwszMSjlRmJlZKScKMzMr5URhZmalnCjMzKyUE4VZE5C0n6RzGx2HWSVOFGYNIKlHo2Mw6yonCrPpJOlISYfmx7+SdHt+vImkyyTtIelxSU9IOq3wvP9KOlPSo8A6kvaX9Kyk+4FvFNbbNT/3UUl31vv1mbXnRGE2/UaT7r4L6Wr3eSTNnuc9C5wGbAKsDqwpaae87tzAfRGxGvA8cCIpQawHDCxs/wRgy7zeDjV+LWadcqIwm34PAl+TNB/wCXAvKWGsD7wL3BEREyJiCnAZsEF+3qfANfnx2oX1JgFXFLZ/N/BHSd8B3ERlDedEYTadImIy8CKwH3APqYaxMbAc6admO/JxRHzahe0fDBwH9AMelLRQN0M26xYnCrMZMxo4ArgzPz4YeBi4H9hQ0sK5w3oPYFSF59+X11soN1vt2rZA0rIRcV9EnED6adp+tX0pZuX8w0VmM2Y0cCxwb0R8IOljYHREvCbpaOAfgIAbIuK69k/O6w0jNVu9CzxSWHyGpOXz828j3RrerGF891gzMyvlpiczMyvlRGFmZqWcKMzMrJQThZmZlXKiMDOzUk4UZmZWyonCzMxKOVGYmVmp/weV+lZKrjY8vAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tdpfNvHcaDB"
      },
      "source": [
        "We have used the LIME interpretation to provide explanations for a recurrent neural network. Looking at the graph we understand that the sentence is negative and the word \"worst\" affects it the most.\n",
        "\n"
      ]
    }
  ]
}